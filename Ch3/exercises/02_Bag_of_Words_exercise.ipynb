{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words Encoding Exercise\n",
    "\n",
    "This notebook demonstrates Bag of Words (BoW) representation using scikit-learn's CountVectorizer on custom text documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed documents:\n",
      "Doc 1: often machine learning tutorials will recommend or require that you prepare your data in specific ways before fitting a machine learning model\n",
      "Doc 2: getting started in applied machine learning can be difficult especially when working with real world data\n",
      "Doc 3: one good example is to use a one hot encoding on categorical data\n"
     ]
    }
   ],
   "source": [
    "# Define the text documents\n",
    "documents = [\n",
    "    \"Often, machine learning tutorials will recommend or require that you prepare your data in specific ways before fitting a machine learning model.\",\n",
    "    \"Getting started in applied machine learning can be difficult, especially when working with real-world data.\",\n",
    "    \"One good example is to use a one-hot encoding on categorical data.\"\n",
    "]\n",
    "\n",
    "# Preprocess: convert to lowercase and remove punctuation\n",
    "processed_docs = [doc.lower().replace(\",\", \"\").replace(\".\", \"\").replace(\"-\", \" \") for doc in documents]\n",
    "\n",
    "print(\"Processed documents:\")\n",
    "for i, doc in enumerate(processed_docs, 1):\n",
    "    print(f\"Doc {i}: {doc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words with Frequency Count\n",
    "\n",
    "BoW represents each document as a vector where each element represents the frequency of a word from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our vocabulary:\n",
      "{'often': 19, 'machine': 17, 'learning': 16, 'tutorials': 31, 'will': 35, 'recommend': 25, 'or': 22, 'require': 26, 'that': 29, 'you': 39, 'prepare': 23, 'your': 40, 'data': 5, 'in': 14, 'specific': 27, 'ways': 33, 'before': 2, 'fitting': 10, 'model': 18, 'getting': 11, 'started': 28, 'applied': 0, 'can': 3, 'be': 1, 'difficult': 6, 'especially': 8, 'when': 34, 'working': 37, 'with': 36, 'real': 24, 'world': 38, 'one': 21, 'good': 12, 'example': 9, 'is': 15, 'to': 30, 'use': 32, 'hot': 13, 'encoding': 7, 'on': 20, 'categorical': 4}\n",
      "\n",
      "Vocabulary size: 41 unique words\n"
     ]
    }
   ],
   "source": [
    "# Build a Bag of Words representation for the corpus\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "bow_rep = count_vect.fit_transform(processed_docs)\n",
    "\n",
    "# Look at the vocabulary mapping\n",
    "print(\"Our vocabulary:\")\n",
    "print(count_vect.vocabulary_)\n",
    "print(f\"\\nVocabulary size: {len(count_vect.vocabulary_)} unique words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary (sorted by index):\n",
      "   0: applied\n",
      "   1: be\n",
      "   2: before\n",
      "   3: can\n",
      "   4: categorical\n",
      "   5: data\n",
      "   6: difficult\n",
      "   7: encoding\n",
      "   8: especially\n",
      "   9: example\n",
      "  10: fitting\n",
      "  11: getting\n",
      "  12: good\n",
      "  13: hot\n",
      "  14: in\n",
      "  15: is\n",
      "  16: learning\n",
      "  17: machine\n",
      "  18: model\n",
      "  19: often\n",
      "  20: on\n",
      "  21: one\n",
      "  22: or\n",
      "  23: prepare\n",
      "  24: real\n",
      "  25: recommend\n",
      "  26: require\n",
      "  27: specific\n",
      "  28: started\n",
      "  29: that\n",
      "  30: to\n",
      "  31: tutorials\n",
      "  32: use\n",
      "  33: ways\n",
      "  34: when\n",
      "  35: will\n",
      "  36: with\n",
      "  37: working\n",
      "  38: world\n",
      "  39: you\n",
      "  40: your\n"
     ]
    }
   ],
   "source": [
    "# Display vocabulary in sorted order\n",
    "print(\"Vocabulary (sorted by index):\")\n",
    "sorted_vocab = sorted(count_vect.vocabulary_.items(), key=lambda x: x[1])\n",
    "for word, idx in sorted_vocab:\n",
    "    print(f\"  {idx:2d}: {word}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW representation for Document 1:\n",
      "[[0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 2 2 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1\n",
      "  0 0 0 1 1]]\n",
      "Shape: (1, 41)\n",
      "\n",
      "BoW representation for Document 2:\n",
      "[[1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      "  1 1 1 0 0]]\n",
      "\n",
      "BoW representation for Document 3:\n",
      "[[0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 2 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      "  0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# See the BoW representation for each document\n",
    "print(\"BoW representation for Document 1:\")\n",
    "print(bow_rep[0].toarray())\n",
    "print(f\"Shape: {bow_rep[0].toarray().shape}\")\n",
    "\n",
    "print(\"\\nBoW representation for Document 2:\")\n",
    "print(bow_rep[1].toarray())\n",
    "\n",
    "print(\"\\nBoW representation for Document 3:\")\n",
    "print(bow_rep[2].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1: 'often machine learning tutorials will recommend or require t...'\n",
      "Words and their frequencies:\n",
      "  before         : 1\n",
      "  data           : 1\n",
      "  fitting        : 1\n",
      "  in             : 1\n",
      "  learning       : 2\n",
      "  machine        : 2\n",
      "  model          : 1\n",
      "  often          : 1\n",
      "  or             : 1\n",
      "  prepare        : 1\n",
      "  recommend      : 1\n",
      "  require        : 1\n",
      "  specific       : 1\n",
      "  that           : 1\n",
      "  tutorials      : 1\n",
      "  ways           : 1\n",
      "  will           : 1\n",
      "  you            : 1\n",
      "  your           : 1\n",
      "\n",
      "Document 2: 'getting started in applied machine learning can be difficult...'\n",
      "Words and their frequencies:\n",
      "  applied        : 1\n",
      "  be             : 1\n",
      "  can            : 1\n",
      "  data           : 1\n",
      "  difficult      : 1\n",
      "  especially     : 1\n",
      "  getting        : 1\n",
      "  in             : 1\n",
      "  learning       : 1\n",
      "  machine        : 1\n",
      "  real           : 1\n",
      "  started        : 1\n",
      "  when           : 1\n",
      "  with           : 1\n",
      "  working        : 1\n",
      "  world          : 1\n",
      "\n",
      "Document 3: 'one good example is to use a one hot encoding on categorical...'\n",
      "Words and their frequencies:\n",
      "  categorical    : 1\n",
      "  data           : 1\n",
      "  encoding       : 1\n",
      "  example        : 1\n",
      "  good           : 1\n",
      "  hot            : 1\n",
      "  is             : 1\n",
      "  on             : 1\n",
      "  one            : 2\n",
      "  to             : 1\n",
      "  use            : 1\n"
     ]
    }
   ],
   "source": [
    "# Show which words appear in each document\n",
    "feature_names = count_vect.get_feature_names_out()\n",
    "\n",
    "for i, doc in enumerate(processed_docs, 1):\n",
    "    print(f\"\\nDocument {i}: '{doc[:60]}...'\")\n",
    "    bow_vector = bow_rep[i-1].toarray()[0]\n",
    "    print(\"Words and their frequencies:\")\n",
    "    for word, freq in zip(feature_names, bow_vector):\n",
    "        if freq > 0:\n",
    "            print(f\"  {word:15s}: {int(freq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New text: 'machine learning is often difficult but good tutorials can help with data preparation'\n",
      "\n",
      "BoW representation: [[0 0 0 1 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      "  1 0 0 0 0]]\n",
      "\n",
      "Words found in vocabulary:\n",
      "  can            : 1\n",
      "  data           : 1\n",
      "  difficult      : 1\n",
      "  good           : 1\n",
      "  is             : 1\n",
      "  learning       : 1\n",
      "  machine        : 1\n",
      "  often          : 1\n",
      "  tutorials      : 1\n",
      "  with           : 1\n"
     ]
    }
   ],
   "source": [
    "# Transform a new text using the learned vocabulary\n",
    "new_text = [\"machine learning is often difficult but good tutorials can help with data preparation\"]\n",
    "new_bow = count_vect.transform(new_text)\n",
    "\n",
    "print(f\"New text: '{new_text[0]}'\")\n",
    "print(f\"\\nBoW representation: {new_bow.toarray()}\")\n",
    "print(\"\\nWords found in vocabulary:\")\n",
    "feature_names = count_vect.get_feature_names_out()\n",
    "for word, freq in zip(feature_names, new_bow.toarray()[0]):\n",
    "    if freq > 0:\n",
    "        print(f\"  {word:15s}: {int(freq)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words with Binary Vectors\n",
    "\n",
    "Instead of word frequencies, we can use binary vectors where 1 indicates the word is present and 0 indicates absence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary BoW representation for all documents:\n",
      "[[0 0 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1\n",
      "  0 0 0 1 1]\n",
      " [1 1 0 1 0 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0\n",
      "  1 1 1 0 0]\n",
      " [0 0 0 0 1 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0\n",
      "  0 0 0 0 0]]\n",
      "\n",
      "Shape: (3, 41) (documents x vocabulary)\n"
     ]
    }
   ],
   "source": [
    "# BoW with binary vectors\n",
    "count_vect_binary = CountVectorizer(binary=True)\n",
    "bow_rep_binary = count_vect_binary.fit_transform(processed_docs)\n",
    "\n",
    "print(\"Binary BoW representation for all documents:\")\n",
    "print(bow_rep_binary.toarray())\n",
    "print(f\"\\nShape: {bow_rep_binary.shape} (documents x vocabulary)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New text: 'machine learning machine learning is good'\n",
      "\n",
      "Binary BoW representation: [[0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]]\n",
      "\n",
      "Note: Even though 'machine' and 'learning' appear twice, they are represented as 1 (present) not 2.\n"
     ]
    }
   ],
   "source": [
    "# Transform new text with binary representation\n",
    "new_text_with_repetition = [\"machine learning machine learning is good\"]\n",
    "new_bow_binary = count_vect_binary.transform(new_text_with_repetition)\n",
    "\n",
    "print(f\"New text: '{new_text_with_repetition[0]}'\")\n",
    "print(f\"\\nBinary BoW representation: {new_bow_binary.toarray()}\")\n",
    "print(\"\\nNote: Even though 'machine' and 'learning' appear twice, they are represented as 1 (present) not 2.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Frequency vs Binary\n",
    "\n",
    "Let's compare how the same text is represented with frequency counting vs binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test text: 'data data data machine learning'\n",
      "\n",
      "Frequency BoW: [[0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]]\n",
      "Binary BoW:    [[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0]]\n",
      "\n",
      "Difference: Frequency BoW shows 'data' appears 3 times, Binary BoW just shows it's present (1).\n"
     ]
    }
   ],
   "source": [
    "# Compare frequency vs binary for a text with repeated words\n",
    "test_text = [\"data data data machine learning\"]\n",
    "\n",
    "# Frequency-based\n",
    "freq_bow = count_vect.transform(test_text)\n",
    "print(f\"Test text: '{test_text[0]}'\")\n",
    "print(f\"\\nFrequency BoW: {freq_bow.toarray()}\")\n",
    "\n",
    "# Binary\n",
    "binary_bow = count_vect_binary.transform(test_text)\n",
    "print(f\"Binary BoW:    {binary_bow.toarray()}\")\n",
    "\n",
    "print(\"\\nDifference: Frequency BoW shows 'data' appears 3 times, Binary BoW just shows it's present (1).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
