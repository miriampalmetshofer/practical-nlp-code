{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "## TF-IDF Exercise\n",
    "\n",
    "This notebook demonstrates TF-IDF encoding on machine learning related sentences.\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) aims to quantify the importance of a given word relative to other words in the document and in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['often machine learning tutorials will recommend or require that you prepare your data in specific ways before fitting a machine learning model',\n",
       " 'getting started in applied machine learning can be difficult especially when working with real world data',\n",
       " 'one good example is to use a one hot encoding on categorical data']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the documents\n",
    "documents = [\n",
    "    \"Often, machine learning tutorials will recommend or require that you prepare your data in specific ways before fitting a machine learning model.\",\n",
    "    \"Getting started in applied machine learning can be difficult, especially when working with real-world data.\",\n",
    "    \"One good example is to use a one-hot encoding on categorical data.\"\n",
    "]\n",
    "\n",
    "# Preprocess the documents (lowercase and remove punctuation)\n",
    "processed_docs = [doc.lower().replace(\".\", \"\").replace(\",\", \"\").replace(\"-\", \" \") for doc in documents]\n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDF for all words in the vocabulary [1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.\n",
      " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.28768207 1.69314718 1.28768207 1.28768207\n",
      " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718\n",
      " 1.69314718 1.69314718 1.69314718 1.69314718 1.69314718]\n",
      "----------\n",
      "All words in the vocabulary ['applied' 'be' 'before' 'can' 'categorical' 'data' 'difficult' 'encoding'\n",
      " 'especially' 'example' 'fitting' 'getting' 'good' 'hot' 'in' 'is'\n",
      " 'learning' 'machine' 'model' 'often' 'on' 'one' 'or' 'prepare' 'real'\n",
      " 'recommend' 'require' 'specific' 'started' 'that' 'to' 'tutorials' 'use'\n",
      " 'ways' 'when' 'will' 'with' 'working' 'world' 'you' 'your']\n",
      "----------\n",
      "TFIDF representation for all documents in our corpus\n",
      " [[0.         0.         0.22057047 0.         0.         0.13027247\n",
      "  0.         0.         0.         0.         0.22057047 0.\n",
      "  0.         0.         0.16774952 0.         0.33549905 0.33549905\n",
      "  0.22057047 0.22057047 0.         0.         0.22057047 0.22057047\n",
      "  0.         0.22057047 0.22057047 0.22057047 0.         0.22057047\n",
      "  0.         0.22057047 0.         0.22057047 0.         0.22057047\n",
      "  0.         0.         0.         0.22057047 0.22057047]\n",
      " [0.2664628  0.2664628  0.         0.2664628  0.         0.15737722\n",
      "  0.2664628  0.         0.2664628  0.         0.         0.2664628\n",
      "  0.         0.         0.20265183 0.         0.20265183 0.20265183\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2664628  0.         0.         0.         0.2664628  0.\n",
      "  0.         0.         0.         0.         0.2664628  0.\n",
      "  0.2664628  0.2664628  0.2664628  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.2737023  0.16165299\n",
      "  0.         0.2737023  0.         0.2737023  0.         0.\n",
      "  0.2737023  0.2737023  0.         0.2737023  0.         0.\n",
      "  0.         0.         0.2737023  0.54740459 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.2737023  0.         0.2737023  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n",
      "----------\n",
      "TFIDF representation for 'machine learning data':\n",
      " [[0.         0.         0.         0.         0.         0.48133417\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.61980538 0.61980538\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "bow_rep_tfidf = tfidf.fit_transform(processed_docs)\n",
    "\n",
    "# IDF for all words in the vocabulary\n",
    "print(\"IDF for all words in the vocabulary\", tfidf.idf_)\n",
    "print(\"-\" * 10)\n",
    "\n",
    "# All words in the vocabulary\n",
    "print(\"All words in the vocabulary\", tfidf.get_feature_names_out())\n",
    "print(\"-\" * 10)\n",
    "\n",
    "# TFIDF representation for all documents in the corpus\n",
    "print(\"TFIDF representation for all documents in our corpus\\n\", bow_rep_tfidf.toarray())\n",
    "print(\"-\" * 10)\n",
    "\n",
    "# Test with a new sentence\n",
    "temp = tfidf.transform([\"machine learning data\"])\n",
    "print(\"TFIDF representation for 'machine learning data':\\n\", temp.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "The TF-IDF representation shows the importance of each word in each document relative to the entire corpus. Words that appear frequently in one document but rarely across all documents will have higher TF-IDF scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
